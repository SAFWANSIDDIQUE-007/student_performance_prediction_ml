{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tabpfn\n",
        "!pip install \"tabpfn-extensions[all] @ git+https://github.com/PriorLabs/tabpfn-extensions.git\""
      ],
      "metadata": {
        "id": "Lg0bn_YCS326"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK6e3hG5qzZK"
      },
      "outputs": [],
      "source": [
        "# 1. Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    r2_score, mean_squared_error, mean_absolute_error,\n",
        "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
        "from tabpfn import TabPFNRegressor\n",
        "from tabpfn import TabPFNClassifier\n",
        "from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70jBUYXDrb_n"
      },
      "outputs": [],
      "source": [
        "# 2. Load Dataset\n",
        "df = pd.read_csv('student-mat.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKdWbEuQkRF7"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFo9_NZ6kVTB"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmtrfkH_rbtQ"
      },
      "outputs": [],
      "source": [
        "# 3. Feature Engineering\n",
        "df['pass_fail'] = (df['G3'] >= 10).astype(int)\n",
        "df['grade_trend'] = df['G2'] - df['G1']\n",
        "bins = [-1, 0, 5, 10, 20, 100]\n",
        "labels = ['0', '1-5', '6-10', '11-20', '21+']\n",
        "df['absences_bin'] = pd.cut(df['absences'], bins=bins, labels=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cnhCTqnrll9"
      },
      "outputs": [],
      "source": [
        "# 4. Exploratory Data Analysis (Plots)\n",
        "plt.figure(figsize=(8, 4))\n",
        "df['G3'].hist(bins=20)\n",
        "plt.title('Final Grade (G3) Distribution')\n",
        "plt.xlabel('Grade')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "df['absences'].hist(bins=30)\n",
        "plt.title('Absences Distribution')\n",
        "plt.xlabel('Absences')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(x='address', y='G3', data=df)\n",
        "plt.title('Final Grades by Address Type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjMRrv1KsG9a"
      },
      "outputs": [],
      "source": [
        "# 5. Define Features & Targets\n",
        "features = df.drop(columns=['grade_trend', 'G1', 'G2', 'G3', 'pass_fail', 'absences'])\n",
        "y_reg = df['G3']\n",
        "y_clf = df['pass_fail']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiYh7sA1sMh5"
      },
      "outputs": [],
      "source": [
        "# 6. Split Dataset\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(features, y_reg, test_size=0.2, random_state=42)\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(features, y_clf, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZGvlTcnsMeg"
      },
      "outputs": [],
      "source": [
        "# 7. Preprocessing\n",
        "numeric_features = features.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = features.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', StandardScaler(), numeric_features),\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSjXBxyEsMb7"
      },
      "outputs": [],
      "source": [
        "# 8. Model Pipelines\n",
        "ridge_model = Pipeline([\n",
        "    ('prep', preprocessor),\n",
        "    ('ridge', Ridge(alpha=1.0))\n",
        "])\n",
        "rf_reg_model = Pipeline([\n",
        "    ('prep', preprocessor),\n",
        "    ('rf_reg', RandomForestRegressor(n_estimators=100))\n",
        "])\n",
        "logreg_model = Pipeline([\n",
        "    ('prep', preprocessor),\n",
        "    ('logreg', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "rf_clf_model = Pipeline([\n",
        "    ('prep', preprocessor),\n",
        "    ('rf_clf', RandomForestClassifier(n_estimators=100))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxXf6CVFsMZh"
      },
      "outputs": [],
      "source": [
        "# 9. Train Models\n",
        "ridge_model.fit(X_train_r, y_train_r)\n",
        "rf_reg_model.fit(X_train_r, y_train_r)\n",
        "logreg_model.fit(X_train_c, y_train_c)\n",
        "rf_clf_model.fit(X_train_c, y_train_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NseTcEWbsMXH"
      },
      "outputs": [],
      "source": [
        "# 10. Predictions\n",
        "y_pred_ridge = ridge_model.predict(X_test_r)\n",
        "y_pred_rf_reg = rf_reg_model.predict(X_test_r)\n",
        "y_pred_logreg = logreg_model.predict(X_test_c)\n",
        "y_pred_rf_clf = rf_clf_model.predict(X_test_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnMeaCJEsMUy"
      },
      "outputs": [],
      "source": [
        "# 11. Evaluation\n",
        "print(\"Regression (Ridge):\")\n",
        "ridge_r2 = r2_score(y_test_r, y_pred_ridge)\n",
        "ridge_rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_ridge))\n",
        "ridge_mae = mean_absolute_error(y_test_r, y_pred_ridge)\n",
        "print(\"R2:\", ridge_r2)\n",
        "print(\"RMSE:\", ridge_rmse)\n",
        "print(\"MAE:\", ridge_mae)\n",
        "\n",
        "print(\"\\nRegression (Random Forest):\")\n",
        "rf_r2 = r2_score(y_test_r, y_pred_rf_reg)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_rf_reg))\n",
        "rf_mae = mean_absolute_error(y_test_r, y_pred_rf_reg)\n",
        "print(\"R2:\", rf_r2)\n",
        "print(\"RMSE:\", rf_rmse)\n",
        "print(\"MAE:\", rf_mae)\n",
        "\n",
        "\n",
        "print(\"\\nClassification (Logistic Regression):\")\n",
        "logreg_accuracy = accuracy_score(y_test_c, y_pred_logreg)\n",
        "logreg_precision = precision_score(y_test_c, y_pred_logreg)\n",
        "logreg_recall = recall_score(y_test_c, y_pred_logreg)\n",
        "logreg_f1 = f1_score(y_test_c, y_pred_logreg)\n",
        "logreg_conf_matrix = confusion_matrix(y_test_c, y_pred_logreg)\n",
        "print(\"Accuracy:\", logreg_accuracy)\n",
        "print(\"Precision:\", logreg_precision)\n",
        "print(\"Recall:\", logreg_recall)\n",
        "print(\"F1 Score:\", logreg_f1)\n",
        "print(\"Confusion Matrix:\\n\", logreg_conf_matrix)\n",
        "\n",
        "print(\"\\nClassification (Random Forest):\")\n",
        "rf_clf_accuracy = accuracy_score(y_test_c, y_pred_rf_clf)\n",
        "rf_clf_precision = precision_score(y_test_c, y_pred_rf_clf)\n",
        "rf_clf_recall = recall_score(y_test_c, y_pred_rf_clf)\n",
        "rf_clf_f1 = f1_score(y_test_c, y_pred_rf_clf)\n",
        "rf_clf_conf_matrix = confusion_matrix(y_test_c, y_pred_rf_clf)\n",
        "print(\"Accuracy:\", rf_clf_accuracy)\n",
        "print(\"Precision:\", rf_clf_precision)\n",
        "print(\"Recall:\", rf_clf_recall)\n",
        "print(\"F1 Score:\", rf_clf_f1)\n",
        "print(\"Confusion Matrix:\\n\", rf_clf_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxsv6M-9XMhz"
      },
      "outputs": [],
      "source": [
        "# Determine input feature dimension\n",
        "input_dim = X_train_r.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3rQ-pLDZcJk"
      },
      "outputs": [],
      "source": [
        "#12. Preprocessing for Neural Network\n",
        "X_train_r_processed = preprocessor.fit_transform(X_train_r)\n",
        "X_test_r_processed = preprocessor.transform(X_test_r)\n",
        "X_train_c_processed = preprocessor.transform(X_train_c)\n",
        "X_test_c_processed = preprocessor.transform(X_test_c)\n",
        "# Convert to numpy arrays and ensure numeric types\n",
        "X_train_r_processed = X_train_r_processed.astype(np.float32)\n",
        "X_test_r_processed = X_test_r_processed.astype(np.float32)\n",
        "y_train_r = y_train_r.astype(np.float32)\n",
        "y_test_r = y_test_r.astype(np.float32)\n",
        "X_train_c_processed = X_train_c_processed.astype(np.float32)\n",
        "X_test_c_processed = X_test_c_processed.astype(np.float32)\n",
        "y_train_c = y_train_c.astype(np.float32)\n",
        "y_test_c = y_test_c.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyO2nlqlXMfP"
      },
      "outputs": [],
      "source": [
        "# 13. Neural Network for Regression (Predicting Final Grade G3)\n",
        "# Define the regression model architecture\n",
        "model_reg = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_r_processed.shape[1],)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the regression model\n",
        "model_reg.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "# Using Mean Squared Error (MSE) loss for regression; tracking Mean Absolute Error (MAE) as a metric\n",
        "model_reg.summary()  # Print model architecture summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG--Pep9XMRQ"
      },
      "outputs": [],
      "source": [
        "# Train the regression model\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history_reg = model_reg.fit(X_train_r_processed, y_train_r,\n",
        "                            validation_split=0.1,  # use 10% of training data for validation\n",
        "                            epochs=100,\n",
        "                            batch_size=32,\n",
        "                            callbacks=[early_stop],\n",
        "                            verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRP0NP-ZXMOS"
      },
      "outputs": [],
      "source": [
        "# Evaluate the regression model on the test set\n",
        "y_pred_reg = model_reg.predict(X_test_r_processed).flatten()  # Predict and flatten to 1D array\n",
        "\n",
        "# Calculate performance metrics for regression\n",
        "r2 = r2_score(y_test_r, y_pred_reg)\n",
        "mse = mean_squared_error(y_test_r, y_pred_reg)\n",
        "rmse = np.sqrt(mse)\n",
        "mae_val = mean_absolute_error(y_test_r, y_pred_reg)\n",
        "\n",
        "print(\"Regression model performance on test set:\")\n",
        "print(f\"R^2 Score: {r2:.3f}\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"MAE: {mae_val:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5gpSBRDfz-O"
      },
      "outputs": [],
      "source": [
        "# Plotting training history (loss) for the regression model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_reg.history['loss'], label='Training Loss (MSE)')\n",
        "plt.plot(history_reg.history['val_loss'], label='Validation Loss (MSE)')\n",
        "plt.title('Regression Model Loss per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training history (metric - MAE) for the regression model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_reg.history['mae'], label='Training MAE')\n",
        "plt.plot(history_reg.history['val_mae'], label='Validation MAE')\n",
        "plt.title('Regression Model MAE per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error (MAE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16143e6d"
      },
      "outputs": [],
      "source": [
        "# 14. Neural Network for Classification (Predicting Pass/Fail)\n",
        "# Define model\n",
        "model_clf = keras.Sequential([\n",
        "    layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train_c_processed.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Dense(16, kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "# Compile model with explicitly named metrics\n",
        "model_clf.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',  # 'accuracy' is already a consistent key\n",
        "        tf.keras.metrics.Precision(name='precision'),  # Explicitly name Precision\n",
        "        tf.keras.metrics.Recall(name='recall')        # Explicitly name Recall\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_clf.summary() # Print model architecture summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwAFwuWUvpbB"
      },
      "outputs": [],
      "source": [
        "# Train the classification model\n",
        "early_stop_clf = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # Increased patience\n",
        "history_clf = model_clf.fit(X_train_c_processed, y_train_c,\n",
        "                            validation_split=0.1,  # use 10% of training data for validation\n",
        "                            epochs=200, # Increased epochs, relies on early stopping\n",
        "                            batch_size=32,\n",
        "                            callbacks=[early_stop_clf],\n",
        "                            verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGvbYYOAv1US"
      },
      "outputs": [],
      "source": [
        "# Evaluate the classification model on the test set\n",
        "y_pred_proba_clf = model_clf.predict(X_test_c_processed)\n",
        "y_pred_clf_nn = (y_pred_proba_clf > 0.5).astype(int).flatten() # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate performance metrics for classification\n",
        "nn_clf_accuracy = accuracy_score(y_test_c, y_pred_clf_nn)\n",
        "nn_clf_precision = precision_score(y_test_c, y_pred_clf_nn)\n",
        "nn_clf_recall = recall_score(y_test_c, y_pred_clf_nn)\n",
        "nn_clf_f1 = f1_score(y_test_c, y_pred_clf_nn)\n",
        "nn_clf_conf_matrix = confusion_matrix(y_test_c, y_pred_clf_nn)\n",
        "\n",
        "print(\"\\nNeural Network Classification model performance on test set:\")\n",
        "print(f\"Accuracy: {nn_clf_accuracy:.3f}\")\n",
        "print(f\"Precision: {nn_clf_precision:.3f}\")\n",
        "print(f\"Recall: {nn_clf_recall:.3f}\")\n",
        "print(f\"F1 Score: {nn_clf_f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", nn_clf_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UaNtPPGRSc4"
      },
      "outputs": [],
      "source": [
        "# Plotting training history (loss) for the classification model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_clf.history['loss'], label='Training Loss (Binary Crossentropy)')\n",
        "plt.plot(history_clf.history['val_loss'], label='Validation Loss (Binary Crossentropy)')\n",
        "plt.title('Classification Model Loss per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Binary Crossentropy Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training history (accuracy) for the classification model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_clf.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_clf.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Classification Model Accuracy per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training history (Precision) for the classification model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_clf.history['precision'], label='Training Precision')\n",
        "plt.plot(history_clf.history['val_precision'], label='Validation Precision')\n",
        "plt.title('Classification Model Precision per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training history (Recall) for the classification model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_clf.history['recall'], label='Training Recall')\n",
        "plt.plot(history_clf.history['val_recall'], label='Validation Recall')\n",
        "plt.title('Classification Model Recall per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyITrpVxjZok"
      },
      "outputs": [],
      "source": [
        "#15. TabPFN Regression Model\n",
        "# Use the preprocessor to handle categorical and numerical features\n",
        "X_train_processed_tabpfn = preprocessor.transform(X_train_r)\n",
        "X_test_processed_tabpfn = preprocessor.transform(X_test_r)\n",
        "\n",
        "# Convert to numpy arrays and ensure float32 type as required by TabPFN\n",
        "X_train_arr = X_train_processed_tabpfn.astype('float32')\n",
        "X_test_arr = X_test_processed_tabpfn.astype('float32')\n",
        "\n",
        "y_train_arr = y_train_r.to_numpy().astype('float32')\n",
        "y_test_arr = y_test_r.to_numpy().astype('float32')\n",
        "\n",
        "\n",
        "# Train the TabPFN model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "reg = TabPFNRegressor(device=device)\n",
        "reg.fit(X_train_arr, y_train_arr)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_tabpfn_reg = reg.predict(X_test_arr)\n",
        "print(\"TabPFN Regressor RMSE:\", np.sqrt(mean_squared_error(y_test_arr, y_pred_tabpfn_reg)))\n",
        "print(\"TabPFN Regressor R²:\", r2_score(y_test_arr, y_pred_tabpfn_reg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db67f9da"
      },
      "outputs": [],
      "source": [
        "#16. Auto TabPFN Rgression Model\n",
        "\n",
        "auto_reg = AutoTabPFNRegressor(max_time=120, device=device)\n",
        "\n",
        "# Apply preprocessing to X_train_r and X_test_r (original DataFrames)\n",
        "X_train_processed = preprocessor.transform(X_train_r)\n",
        "X_test_processed = preprocessor.transform(X_test_r)\n",
        "\n",
        "auto_reg.fit(X_train_processed, y_train_r.values)\n",
        "y_pred2 = auto_reg.predict(X_test_processed)\n",
        "print(\"AutoTabPFNRegressor RMSE:\", np.sqrt(mean_squared_error(y_test_r, y_pred2)))\n",
        "print(\"AutoTabPFNRegressor R²:\", r2_score(y_test_r, y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVFND79SH4U8"
      },
      "outputs": [],
      "source": [
        "#17. TabPFN Classification Model\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['grade_trend', 'G1', 'G2', 'G3', 'pass_fail', 'absences']), y_clf, test_size=0.2)\n",
        "clf = TabPFNClassifier()  # v2 used by default\n",
        "\n",
        "clf.fit(X_train.values, y_train.values)\n",
        "y_pred = clf.predict(X_test.values)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4HpGgLPogVj"
      },
      "outputs": [],
      "source": [
        "#18. Comparison between all Regression models\n",
        "\n",
        "# Add TabPFN Regressor results to the comparison\n",
        "models = ['Ridge', 'Random Forest', 'Neural Network', 'TabPFN', 'AutoTabPFN']\n",
        "r2_scores = [ridge_r2, rf_r2, r2, r2_score(y_test_arr, y_pred_tabpfn_reg), r2_score(y_test_r, y_pred2)]\n",
        "rmse_scores = [ridge_rmse, rf_rmse, rmse, np.sqrt(mean_squared_error(y_test_arr, y_pred_tabpfn_reg)), np.sqrt(mean_squared_error(y_test_r, y_pred2))]\n",
        "\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10,6)) # Increase figure size\n",
        "ax1.bar(models, r2_scores, color=['skyblue','lightgreen','salmon', 'gold', 'purple'], label='R²') # Added colors\n",
        "ax1.set_ylabel('R² Score')\n",
        "ax1.set_ylim(0, max(r2_scores)+0.1)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(models, rmse_scores, color='darkgray', marker='o', linestyle='-', label='RMSE') # Added linestyle\n",
        "ax2.set_ylabel('RMSE')\n",
        "ax2.set_ylim(0, max(rmse_scores)+1)\n",
        "\n",
        "ax1.set_title(\"Regression Model Comparison\")\n",
        "ax1.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "plt.grid(True) # Added grid\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U40WA7BIo73R"
      },
      "outputs": [],
      "source": [
        "#19. Comparison between all Classification models\n",
        "\n",
        "# TabPFN Classification\n",
        "X_train_c_processed_tabpfn = preprocessor.transform(X_train_c)\n",
        "X_test_c_processed_tabpfn = preprocessor.transform(X_test_c)\n",
        "\n",
        "# Convert to numpy arrays for TabPFNClassifier\n",
        "X_train_c_arr = X_train_c_processed_tabpfn.astype('float32')\n",
        "X_test_c_arr = X_test_c_processed_tabpfn.astype('float32')\n",
        "\n",
        "y_train_c_arr = y_train_c.to_numpy()\n",
        "y_test_c_arr = y_test_c.to_numpy()\n",
        "\n",
        "# Instantiate and train TabPFNClassifier\n",
        "clf_tabpfn = TabPFNClassifier(device=device)\n",
        "\n",
        "# TabPFNClassifier expects numpy arrays\n",
        "clf_tabpfn.fit(X_train_c_arr, y_train_c_arr)\n",
        "\n",
        "# Predict with TabPFNClassifier\n",
        "y_pred_tabpfn_clf = clf_tabpfn.predict(X_test_c_arr)\n",
        "\n",
        "# Evaluate TabPFNClassifier\n",
        "tabpfn_clf_accuracy = accuracy_score(y_test_c_arr, y_pred_tabpfn_clf)\n",
        "tabpfn_clf_precision = precision_score(y_test_c_arr, y_pred_tabpfn_clf)\n",
        "tabpfn_clf_recall = recall_score(y_test_c_arr, y_pred_tabpfn_clf)\n",
        "tabpfn_clf_f1 = f1_score(y_test_c_arr, y_pred_tabpfn_clf)\n",
        "tabpfn_clf_conf_matrix = confusion_matrix(y_test_c_arr, y_pred_tabpfn_clf)\n",
        "\n",
        "print(\"\\nTabPFN Classification model performance on test set:\")\n",
        "print(f\"Accuracy: {tabpfn_clf_accuracy:.3f}\")\n",
        "print(f\"Precision: {tabpfn_clf_precision:.3f}\")\n",
        "print(f\"Recall: {tabpfn_clf_recall:.3f}\")\n",
        "print(f\"F1 Score: {tabpfn_clf_f1:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", tabpfn_clf_conf_matrix)\n",
        "\n",
        "\n",
        "# Plot comparison between all classification models including TabPFN\n",
        "labels_clf = ['Logistic Regression', 'Random Forest', 'Neural Network', 'TabPFN']\n",
        "acc_scores_clf = [logreg_accuracy, rf_clf_accuracy, nn_clf_accuracy, tabpfn_clf_accuracy]\n",
        "f1_scores_clf = [logreg_f1, rf_clf_f1, nn_clf_f1, tabpfn_clf_f1]\n",
        "\n",
        "x_clf = np.arange(len(labels_clf))\n",
        "width_clf = 0.35\n",
        "\n",
        "fig_clf, ax_clf = plt.subplots(figsize=(10,6))\n",
        "rects1 = ax_clf.bar(x_clf - width_clf/2, acc_scores_clf, width_clf, label='Accuracy', color=['steelblue', 'lightgreen', 'salmon', 'gold'])\n",
        "rects2 = ax_clf.bar(x_clf + width_clf/2, f1_scores_clf, width_clf, label='F1 Score', color=['deepskyblue', 'limegreen', 'tomato', 'orange'])\n",
        "\n",
        "ax_clf.set_xticks(x_clf)\n",
        "ax_clf.set_xticklabels(labels_clf)\n",
        "ax_clf.set_ylim(0,1.1)\n",
        "ax_clf.set_ylabel('Score')\n",
        "ax_clf.set_title(\"Classification Model Comparison\")\n",
        "ax_clf.legend()\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax_clf.annotate('%.2f' % height,\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNgPLpcOpisn"
      },
      "outputs": [],
      "source": [
        "#20. Confusion matrices of all Classification models\n",
        "\n",
        "# Create confusion matrix plots for all classification models\n",
        "fig, axes = plt.subplots(1,4, figsize=(20,5)) # Adjusted figure size for 4 plots\n",
        "y_preds = [y_pred_logreg, y_pred_rf_clf, y_pred_clf_nn, y_pred_tabpfn_clf]\n",
        "titles = ['Logistic Regression', 'Random Forest', 'Neural Network', 'TabPFN']\n",
        "\n",
        "for ax, y_p, t in zip(axes, y_preds, titles):\n",
        "    # Ensure the predictions and true labels are the same type for confusion_matrix\n",
        "    # For NN and TabPFN, predictions are already arrays. For others, convert if needed.\n",
        "    cm = confusion_matrix(y_test_c, y_p)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False)\n",
        "    ax.set_title(f'{t} Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('Actual')\n",
        "    # Add class labels (assuming 0 and 1)\n",
        "    ax.set_xticklabels(['Fail', 'Pass'])\n",
        "    ax.set_yticklabels(['Fail', 'Pass'])\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Important features from different Classification models\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import copy\n",
        "\n",
        "def permutation_importance_regression_nn(model, X_test, y_test, preprocessor, n_repeats=5):\n",
        "    \"\"\"\n",
        "    Calculates permutation importance for a Keras regression model.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras regression model.\n",
        "        X_test: Original test DataFrame (before preprocessing).\n",
        "        y_test: True test target values.\n",
        "        preprocessor: The fitted ColumnTransformer.\n",
        "        n_repeats: Number of times to permute each feature.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with feature names as keys and mean importance score as values.\n",
        "    \"\"\"\n",
        "    # Get the baseline performance\n",
        "    X_test_processed = preprocessor.transform(X_test).astype(np.float32)\n",
        "    baseline_pred = model.predict(X_test_processed).flatten()\n",
        "    baseline_loss = mean_squared_error(y_test, baseline_pred)\n",
        "\n",
        "    feature_importance = {}\n",
        "    # Get the feature names after preprocessing\n",
        "    feature_names_processed = preprocessor.get_feature_names_out()\n",
        "\n",
        "    print(\"Calculating permutation importance for Neural Network (this may take a while)...\")\n",
        "\n",
        "    for col in X_test.columns:\n",
        "        print(f\"  Permuting feature: {col}\")\n",
        "        feature_losses = []\n",
        "        for _ in range(n_repeats):\n",
        "            # Create a copy of the original test data\n",
        "            X_test_permuted = X_test.copy()\n",
        "            # Permute the values in the current column\n",
        "            X_test_permuted[col] = np.random.permutation(X_test_permuted[col])\n",
        "\n",
        "            # Preprocess the permuted data\n",
        "            X_test_permuted_processed = preprocessor.transform(X_test_permuted).astype(np.float32)\n",
        "\n",
        "            # Predict with the permuted data\n",
        "            permuted_pred = model.predict(X_test_permuted_processed).flatten()\n",
        "\n",
        "            # Calculate the loss with permuted data\n",
        "            permuted_loss = mean_squared_error(y_test, permuted_pred)\n",
        "            feature_losses.append(permuted_loss)\n",
        "\n",
        "        # Importance is the average increase in loss\n",
        "        feature_importance[col] = np.mean(feature_losses) - baseline_loss\n",
        "\n",
        "    # Sort features by importance\n",
        "    sorted_importance = dict(sorted(feature_importance.items(), key=lambda item: item[1], reverse=True))\n",
        "    return sorted_importance\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 8)) # Adjusted figure size for 3 plots\n",
        "\n",
        "# RF Classifier Importance Plot\n",
        "sns.barplot(x='importance', y='feature', data=rf_imp_df, ax=axes[0], color='teal')\n",
        "axes[0].set_title('Random Forest Classifier Feature Importance (Top 20)')\n",
        "axes[0].set_xlabel('Importance (Gini)')\n",
        "axes[0].set_ylabel('Feature')\n",
        "\n",
        "# Logistic Regression Coefficient Plot\n",
        "sns.barplot(x='importance', y='feature', data=logreg_imp_df, ax=axes[1], color='skyblue')\n",
        "axes[1].set_title('Logistic Regression Feature Importance (Top 20, Absolute Coefficients)')\n",
        "axes[1].set_xlabel('Absolute Coefficient Value')\n",
        "axes[1].set_ylabel('Feature')\n",
        "\n",
        "# NN Regression Permutation Importance Plot\n",
        "sns.barplot(x='importance', y='feature', data=nn_reg_imp_df.head(20), ax=axes[2], color='orangered')\n",
        "axes[2].set_title('Neural Network Regression Permutation Importance (Top 20)')\n",
        "axes[2].set_xlabel('Importance (Increase in MSE)')\n",
        "# Remove ylabel from the third plot for cleaner look as features are the same\n",
        "axes[2].set_ylabel('')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Note: Feature importance for TabPFN is not included as a simple method is not available.\n",
        "# The NN importance shown is based on permutation on the original features, which is an estimate."
      ],
      "metadata": {
        "id": "Jk1qKmOFna1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Create the new student record for testing\n",
        "new_student = pd.DataFrame({\n",
        "    'school': ['GP'], 'sex': ['F'], 'age': [17], 'address': ['U'],\n",
        "    'famsize': ['GT3'], 'Pstatus': ['T'], 'Medu': [2], 'Fedu': [2],\n",
        "    'Mjob': ['services'], 'Fjob': ['other'], 'reason': ['reputation'],\n",
        "    'guardian': ['mother'], 'traveltime': [1], 'studytime': [2],\n",
        "    'failures': [0], 'schoolsup': ['yes'], 'famsup': ['no'], 'paid': ['no'],\n",
        "    'activities': ['yes'], 'nursery': ['yes'], 'higher': ['yes'], 'internet': ['yes'],\n",
        "    'romantic': ['no'], 'famrel': [4], 'freetime': [3], 'goout': [2],\n",
        "    'Dalc': [1], 'Walc': [1], 'health': [4], 'absences_bin': ['1-5']\n",
        "})\n",
        "\n",
        "# Step 2: Ensure column order matches features\n",
        "new_student = new_student[features.columns]  # Safe reorder\n",
        "\n",
        "# Step 3: Preprocess\n",
        "new_student_processed = preprocessor.transform(new_student)\n",
        "\n",
        "# Step 4: Predictions\n",
        "\n",
        "# Regressors\n",
        "print(\"  Regressor Predictions (Grade):\")\n",
        "print(\"  Ridge Regression:           \", round(ridge_model.predict(new_student)[0], 2))\n",
        "print(\"  Random Forest Regressor:    \", round(rf_reg_model.predict(new_student)[0], 2))\n",
        "print(\"  Neural Network Regressor:   \", round(model_reg.predict(new_student_processed)[0][0], 2))\n",
        "print(\"  TabPFN Regressor:           \", round(reg.predict(new_student_processed)[0], 2))\n",
        "print(\"  AutoTabPFN Regressor:       \", round(auto_reg.predict(new_student_processed)[0], 2))\n",
        "\n",
        "# Classifiers\n",
        "print(\"  Classifier Predictions (Pass/Fail):\")\n",
        "print(\"  Logistic Regression:        \", logreg_model.predict(new_student)[0])\n",
        "print(\"  Random Forest Classifier:   \", rf_clf_model.predict(new_student)[0])\n",
        "print(\"  Neural Network Classifier:  \", int(model_clf.predict(new_student_processed)[0][0] > 0.5))\n",
        "print(\"  TabPFN Classifier:          \", clf_tabpfn.predict(new_student_processed)[0])\n",
        "\n",
        "# Probabilities\n",
        "print(\"  Classifier Probabilities of Pass:\")\n",
        "print(\"  Logistic Regression:        \", round(logreg_model.predict_proba(new_student)[0][1], 3))\n",
        "print(\"  Random Forest Classifier:   \", round(rf_clf_model.predict_proba(new_student)[0][1], 3))\n",
        "print(\"  Neural Network Classifier:  \", round(model_clf.predict(new_student_processed)[0][0], 3))\n",
        "print(\"  TabPFN Classifier:          \", round(clf_tabpfn.predict_proba(new_student_processed)[0][1], 3))\n"
      ],
      "metadata": {
        "id": "C017YTRsvKlN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}